{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50dba54f-efc8-4031-aa46-804b285733fa",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e8a93d9-6d50-4866-a8c4-b2d7d6207723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fcb60e-9f3b-4e88-8fc0-fdb3287610f2",
   "metadata": {},
   "source": [
    "# Step 0: Load Dataset\n",
    "**Purpose:** Load the cleaned dataset (with dummy variables, no multicollinearity issues) for modeling.  \n",
    "**Goal:** Prepare `df` as the main DataFrame for train/test splitting.  \n",
    "**Expected Outcome:** A DataFrame ready for model building, all features numeric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cd59988-028e-409d-93e2-7dbecfbc58c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>MultipleLines_No phone service</th>\n",
       "      <th>...</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaperlessBilling_Yes</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>tenure_group_13 - 24</th>\n",
       "      <th>tenure_group_25 - 36</th>\n",
       "      <th>tenure_group_37 - 48</th>\n",
       "      <th>tenure_group_49 - 60</th>\n",
       "      <th>tenure_group_61 - 72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SeniorCitizen  MonthlyCharges  TotalCharges  Churn  \\\n",
       "0           0              0           29.85         29.85      0   \n",
       "1           1              0           56.95       1889.50      0   \n",
       "2           2              0           53.85        108.15      1   \n",
       "3           3              0           42.30       1840.75      0   \n",
       "4           4              0           70.70        151.65      1   \n",
       "\n",
       "   gender_Male  Partner_Yes  Dependents_Yes  PhoneService_Yes  \\\n",
       "0            0            1               0                 0   \n",
       "1            1            0               0                 1   \n",
       "2            1            0               0                 1   \n",
       "3            1            0               0                 0   \n",
       "4            0            0               0                 1   \n",
       "\n",
       "   MultipleLines_No phone service  ...  Contract_Two year  \\\n",
       "0                               1  ...                  0   \n",
       "1                               0  ...                  0   \n",
       "2                               0  ...                  0   \n",
       "3                               1  ...                  0   \n",
       "4                               0  ...                  0   \n",
       "\n",
       "   PaperlessBilling_Yes  PaymentMethod_Credit card (automatic)  \\\n",
       "0                     1                                      0   \n",
       "1                     0                                      0   \n",
       "2                     1                                      0   \n",
       "3                     0                                      0   \n",
       "4                     1                                      0   \n",
       "\n",
       "   PaymentMethod_Electronic check  PaymentMethod_Mailed check  \\\n",
       "0                               1                           0   \n",
       "1                               0                           1   \n",
       "2                               0                           1   \n",
       "3                               0                           0   \n",
       "4                               1                           0   \n",
       "\n",
       "   tenure_group_13 - 24  tenure_group_25 - 36  tenure_group_37 - 48  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     1                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     1   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   tenure_group_49 - 60  tenure_group_61 - 72  \n",
       "0                     0                     0  \n",
       "1                     0                     0  \n",
       "2                     0                     0  \n",
       "3                     0                     0  \n",
       "4                     0                     0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\Data Analytics\\PORTFOLIO PROJECTS\\End to End Machine Learning Project\\self\\telco_data_dummies.csv\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ee3726e-ad45-4a63-91cc-40f903e54a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>MultipleLines_No phone service</th>\n",
       "      <th>MultipleLines_Yes</th>\n",
       "      <th>...</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaperlessBilling_Yes</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>tenure_group_13 - 24</th>\n",
       "      <th>tenure_group_25 - 36</th>\n",
       "      <th>tenure_group_37 - 48</th>\n",
       "      <th>tenure_group_49 - 60</th>\n",
       "      <th>tenure_group_61 - 72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen  MonthlyCharges  TotalCharges  Churn  gender_Male  \\\n",
       "0              0           29.85         29.85      0            0   \n",
       "1              0           56.95       1889.50      0            1   \n",
       "2              0           53.85        108.15      1            1   \n",
       "3              0           42.30       1840.75      0            1   \n",
       "4              0           70.70        151.65      1            0   \n",
       "\n",
       "   Partner_Yes  Dependents_Yes  PhoneService_Yes  \\\n",
       "0            1               0                 0   \n",
       "1            0               0                 1   \n",
       "2            0               0                 1   \n",
       "3            0               0                 0   \n",
       "4            0               0                 1   \n",
       "\n",
       "   MultipleLines_No phone service  MultipleLines_Yes  ...  Contract_Two year  \\\n",
       "0                               1                  0  ...                  0   \n",
       "1                               0                  0  ...                  0   \n",
       "2                               0                  0  ...                  0   \n",
       "3                               1                  0  ...                  0   \n",
       "4                               0                  0  ...                  0   \n",
       "\n",
       "   PaperlessBilling_Yes  PaymentMethod_Credit card (automatic)  \\\n",
       "0                     1                                      0   \n",
       "1                     0                                      0   \n",
       "2                     1                                      0   \n",
       "3                     0                                      0   \n",
       "4                     1                                      0   \n",
       "\n",
       "   PaymentMethod_Electronic check  PaymentMethod_Mailed check  \\\n",
       "0                               1                           0   \n",
       "1                               0                           1   \n",
       "2                               0                           1   \n",
       "3                               0                           0   \n",
       "4                               1                           0   \n",
       "\n",
       "   tenure_group_13 - 24  tenure_group_25 - 36  tenure_group_37 - 48  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     1                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     1   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   tenure_group_49 - 60  tenure_group_61 - 72  \n",
       "0                     0                     0  \n",
       "1                     0                     0  \n",
       "2                     0                     0  \n",
       "3                     0                     0  \n",
       "4                     0                     0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d0c94-1a0b-4282-926a-cdf446c39ffd",
   "metadata": {},
   "source": [
    "# Step 1 – Train-Test Split\n",
    "**Purpose:** Split data into training and testing sets while preserving class distribution.  \n",
    "**Goal:** Create X_train, X_test, y_train, y_test with 80/20 split.  \n",
    "**Expected Outcome:** Training and testing sets with same churn ratio as original data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77f0c80c-2a89-41ed-b860-f1e6f4366091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5625, 34)\n",
      "X_test shape: (1407, 34)\n",
      "y_train distribution:\n",
      " Churn\n",
      "0    0.734222\n",
      "1    0.265778\n",
      "Name: proportion, dtype: float64\n",
      "y_test distribution:\n",
      " Churn\n",
      "0    0.734186\n",
      "1    0.265814\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define X and y\n",
    "X = df.drop(columns=[\"Churn\"])\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "# Split 80/20 with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y   # keeps churn ratio same in train/test\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"y_test distribution:\\n\", y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b3a372-4d90-49f6-a285-959ccd3f45c8",
   "metadata": {},
   "source": [
    "# Step 2: Baseline Dummy Classifier\n",
    "**Purpose:** Establish a naive baseline by always predicting the majority class (non-churn).  \n",
    "**Goal:** Evaluate minimum performance; any real model should outperform this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f9e9a8b-a019-4176-a1ba-51a790206ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1033    0]\n",
      " [ 374    0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7342    1.0000    0.8467      1033\n",
      "           1     0.0000    0.0000    0.0000       374\n",
      "\n",
      "    accuracy                         0.7342      1407\n",
      "   macro avg     0.3671    0.5000    0.4234      1407\n",
      "weighted avg     0.5390    0.7342    0.6217      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Use most frequent class as prediction (always predicts 0 = no churn)\n",
    "baseline = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
    "baseline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_baseline = baseline.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_baseline))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(\n",
    "    y_test, y_pred_baseline, digits=4, zero_division=0\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9323ed-2e34-4036-ac47-ea89a836da47",
   "metadata": {},
   "source": [
    "**Interpretation:**  \n",
    "Confusion Matrix:\n",
    "[[1033    0]\n",
    " [ 374    0]]\n",
    "\n",
    "- Predicts all customers as non-churn.  \n",
    "- Correctly identifies non-churn (1033 TN), fails to identify churn (0 TP).  \n",
    "\n",
    "Classification Report:\n",
    "- Accuracy: 0.7342 → appears good due to class imbalance.  \n",
    "- Recall for churn = 0 → model misses all churned customers.  \n",
    "- F1-score for churn = 0 → poor performance for minority class.  \n",
    "\n",
    "✅ Key takeaway:  \n",
    "- DummyClassifier sets the **baseline performance**.  \n",
    "- Any real model must **improve recall/F1 for churn**, not just accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f16b28-0afc-43b2-b97e-8871afaf795b",
   "metadata": {},
   "source": [
    "# Step 3: Decision Tree Classifier\n",
    "**Purpose:** Train a simple tree-based model to predict churn, capturing non-linear patterns.  \n",
    "**Goal:** Compare with baseline DummyClassifier; check if it starts detecting churned customers.  \n",
    "**Note:** Decision Trees can overfit easily, so later we may tune max_depth or min_samples_leaf.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57e22ea7-361f-45e2-ad77-50a3d13656e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[837 196]\n",
      " [188 186]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8166    0.8103    0.8134      1033\n",
      "           1     0.4869    0.4973    0.4921       374\n",
      "\n",
      "    accuracy                         0.7271      1407\n",
      "   macro avg     0.6517    0.6538    0.6527      1407\n",
      "weighted avg     0.7290    0.7271    0.7280      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize Decision Tree\n",
    "# class_weight=\"balanced\" to handle class imbalance\n",
    "dtree = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "# Train\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_tree = dtree.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tree))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(\n",
    "    y_test, y_pred_tree, digits=4, zero_division=0\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f230f5df-1c54-432b-b461-203200239f99",
   "metadata": {},
   "source": [
    " **Interpretation: Decision Tree Classifier**\n",
    "\n",
    "Confusion Matrix: TN=837, FP=196, FN=188, TP=186\n",
    "\n",
    "Classification Report Highlights:\n",
    "- Accuracy: 0.7271 → slight drop vs baseline.\n",
    "- Recall for churn: 0.4973 (~50% of churned customers detected)\n",
    "- Precision for churn: 0.4869\n",
    "- F1-score for churn: 0.4921 → moderate performance for minority class.\n",
    "\n",
    "Key Takeaways:\n",
    "- Decision Tree captures patterns to detect churn.\n",
    "- Accuracy drops slightly, but recall/F1 for churn improves significantly.\n",
    "- Model is actionable and sets the stage for further improvement with ensemble methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc5e85-a426-48a0-b824-bfa76dd887a4",
   "metadata": {},
   "source": [
    "# Step 4a: Random Forest Classifier\n",
    "**Purpose:** Train an ensemble of decision trees to improve churn prediction over a single Decision Tree.  \n",
    "**Goal:** Capture complex patterns, reduce overfitting, and improve recall/F1 for churned customers.  \n",
    "**Notes:** \n",
    "- Use `class_weight=\"balanced\"` to handle class imbalance.\n",
    "- Default hyperparameters are a starting point; later can tune max_depth, n_estimators, min_samples_leaf, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a60a733f-77fc-46c2-b5c7-e8b760e01cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[915 118]\n",
      " [197 177]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8228    0.8858    0.8531      1033\n",
      "           1     0.6000    0.4733    0.5291       374\n",
      "\n",
      "    accuracy                         0.7761      1407\n",
      "   macro avg     0.7114    0.6795    0.6911      1407\n",
      "weighted avg     0.7636    0.7761    0.7670      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,       # 100 trees\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "# Train on training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(\n",
    "    y_test, y_pred_rf, digits=4, zero_division=0\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6720d2-330f-4096-9f6e-ee7055aa60ad",
   "metadata": {},
   "source": [
    "**Interpretation: Random Forest Classifier**\n",
    "\n",
    "Confusion Matrix:**  \n",
    "TN=915, FP=118, FN=197, TP=177\n",
    "\n",
    "Classification Report Highlights:\n",
    "- Accuracy: 0.7761 → overall correctness improved over Decision Tree (0.7271)  \n",
    "- Recall for churn: 0.4733 → ~47% of churned customers detected  \n",
    "- Precision for churn: 0.6000 → more reliable predictions, fewer false alarms  \n",
    "- F1-score for churn: 0.5291 → better balance between precision and recall  \n",
    "\n",
    "Macro / Weighted Average:  \n",
    "- Macro avg F1 = 0.6911 → average performance across both classes  \n",
    "- Weighted avg F1 = 0.7670 → overall performance weighted by class sizes  \n",
    "\n",
    "Key Takeaways:\n",
    "- Random Forest improves precision and F1-score for churn over Decision Tree.  \n",
    "- Accuracy improved while maintaining reasonable detection of churn.  \n",
    "- Model is more robust and actionable for real-world churn prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c5b259-04c7-4a18-9368-81466dfb734e",
   "metadata": {},
   "source": [
    "**Improvement / Next Steps**\n",
    "\n",
    "Even though the Random Forest performs better than a single Decision Tree, churn recall/F1 can still improve. Possible steps:  \n",
    "\n",
    "- **Hyperparameter Tuning:**  \n",
    "  - Adjust `n_estimators`, `max_depth`, `min_samples_leaf`, `min_samples_split` to reduce overfitting and improve minority class detection.  \n",
    "\n",
    "- **Class Balancing Techniques:**  \n",
    "  - Oversampling (SMOTE) or undersampling to give the model more churn examples.  \n",
    "\n",
    "- **Threshold Adjustment:**  \n",
    "  - Change the probability cutoff for predicting churn to increase recall.  \n",
    "\n",
    "- **Try Stronger Models:**  \n",
    "  - Gradient Boosting, XGBoost, or LightGBM may capture more complex patterns and further boost F1 for churn.  \n",
    "\n",
    "> These steps help shift focus to **better detecting churn** while maintaining overall model reliability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714ff549-6442-451c-8d04-f461d8ee2bf0",
   "metadata": {},
   "source": [
    "# Step 4b: Random Forest – Hyperparameter Tuning & Threshold Adjustment\n",
    "\n",
    "**Purpose:** Improve Random Forest performance, especially **recall/F1 for churn**, using hyperparameter tuning and probability threshold adjustment.  \n",
    "**Goal:** Capture more churned customers while keeping predictions reliable.  \n",
    "**Notes:** \n",
    "- Tuning parameters like `n_estimators`, `max_depth`, `min_samples_leaf` can reduce overfitting.  \n",
    "- Adjusting the classification threshold can favor predicting churn to improve recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a32ae386-4f1e-4d64-beb7-dbca21afcb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# GridSearch with 3-fold CV\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42, class_weight=\"balanced\"),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1',       # focus on minority class\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_rf.best_params_)\n",
    "\n",
    "# Predict with best model\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa614439-8294-404b-b9f6-a6173aa7af31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[761 272]\n",
      " [ 85 289]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8995    0.7367    0.8100      1033\n",
      "           1     0.5152    0.7727    0.6182       374\n",
      "\n",
      "    accuracy                         0.7463      1407\n",
      "   macro avg     0.7073    0.7547    0.7141      1407\n",
      "weighted avg     0.7974    0.7463    0.7590      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4b: Tuned Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1️⃣ Define best parameters from GridSearchCV\n",
    "best_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 4,\n",
    "    'random_state': 42,\n",
    "    'class_weight': 'balanced'\n",
    "}\n",
    "\n",
    "# 2️⃣ Initialize the Random Forest with best parameters\n",
    "tuned_rf = RandomForestClassifier(**best_params)\n",
    "\n",
    "# 3️⃣ Train the model on training data\n",
    "tuned_rf.fit(X_train, y_train)\n",
    "\n",
    "# 4️⃣ Predict on test data\n",
    "y_pred_tuned = tuned_rf.predict(X_test)\n",
    "\n",
    "# 5️⃣ Evaluate performance\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tuned))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(\n",
    "    y_test, y_pred_tuned, digits=4, zero_division=0\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f946a99-6ea6-4cb1-85bf-200d28892886",
   "metadata": {},
   "source": [
    " **Random Forest – Hyperparameter Tuning (Interpretation)**\n",
    "\n",
    "Confusion Matrix:\n",
    "- **True Negatives (TN) = 761** → correctly predicted non-churn  \n",
    "- **False Positives (FP) = 272** → predicted churn but actually non-churn  \n",
    "- **False Negatives (FN) = 85** → predicted non-churn but actually churn  \n",
    "- **True Positives (TP) = 289** → correctly predicted churn  \n",
    "\n",
    "**Classification Report Highlights:**  \n",
    "- Accuracy: 0.7463 → slight improvement over untuned RF  \n",
    "- Recall (Churn): 0.7727 → most churners correctly detected  \n",
    "- Precision (Churn): 0.5152 → moderate; some false positives exist  \n",
    "- F1-score (Churn): 0.6182 → balanced performance  \n",
    "- Weighted F1: 0.7590 → good overall metric considering class imbalance  \n",
    "\n",
    "**Key Takeaways:**  \n",
    "- Tuned RF captures **more churners** than baseline and untuned RF.  \n",
    "- High recall indicates the model is effective in detecting churn.  \n",
    "- F1-score shows **moderate performance**, precision trade-off is acceptable.  \n",
    "- Ready for deployment: interpretable, stable, and actionable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95431b7-5189-43dc-a980-a6d212fe5c87",
   "metadata": {},
   "source": [
    "### Step 5: Boosting Model (XGBoost)\n",
    "\n",
    "**Purpose:**  \n",
    "Use gradient boosting to capture complex patterns missed by Random Forest; sequentially focus on misclassified samples.\n",
    "\n",
    "**Goal:**  \n",
    "Improve overall accuracy and weighted F1 while maintaining high recall for churn.\n",
    "\n",
    "**Notes:**  \n",
    "- Parameters: `n_estimators=200`, `max_depth=6`, `learning_rate=0.1`, `scale_pos_weight` to handle class imbalance.  \n",
    "- Captures non-linear interactions and subtle patterns in the data.  \n",
    "- Confusion matrix and classification report show improved weighted performance; recall for churn remains high.  \n",
    "- Slightly more complex and less interpretable than Random Forest; still strong for deployment/demo purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "93c9e01b-2a3a-43a5-9bcc-ade452c28e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-3.0.4-py3-none-win_amd64.whl (56.8 MB)\n",
      "   ---------------------------------------- 0.0/56.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/56.8 MB 6.7 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 2.1/56.8 MB 5.9 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 3.4/56.8 MB 5.9 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 4.5/56.8 MB 6.0 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 6.0/56.8 MB 6.1 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 7.1/56.8 MB 6.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 8.4/56.8 MB 6.0 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 9.7/56.8 MB 6.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 11.0/56.8 MB 6.2 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 12.3/56.8 MB 6.2 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 13.9/56.8 MB 6.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 15.2/56.8 MB 6.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 16.5/56.8 MB 6.3 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 17.8/56.8 MB 6.2 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 19.1/56.8 MB 6.3 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 20.4/56.8 MB 6.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 21.8/56.8 MB 6.3 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 23.1/56.8 MB 6.3 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 24.4/56.8 MB 6.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 25.7/56.8 MB 6.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 27.0/56.8 MB 6.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 28.3/56.8 MB 6.3 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 29.6/56.8 MB 6.3 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 30.9/56.8 MB 6.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 32.2/56.8 MB 6.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 33.8/56.8 MB 6.3 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 35.1/56.8 MB 6.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 36.4/56.8 MB 6.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 38.0/56.8 MB 6.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 39.3/56.8 MB 6.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 40.6/56.8 MB 6.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 41.9/56.8 MB 6.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 43.3/56.8 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 44.6/56.8 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 45.6/56.8 MB 6.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 46.9/56.8 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 48.5/56.8 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 49.8/56.8 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 51.1/56.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 52.4/56.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 53.7/56.8 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 55.3/56.8 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.6/56.8 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.6/56.8 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 56.8/56.8 MB 6.2 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.4\n"
     ]
    }
   ],
   "source": [
    "# Install XGBoost \n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0fadcfc7-1a76-4ff0-8fca-3fee78bd9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[779 254]\n",
      " [ 95 279]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8913    0.7541    0.8170      1033\n",
      "           1     0.5235    0.7460    0.6152       374\n",
      "\n",
      "    accuracy                         0.7520      1407\n",
      "   macro avg     0.7074    0.7501    0.7161      1407\n",
      "weighted avg     0.7935    0.7520    0.7634      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: XGBoost Classifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize XGBoost with basic parameters\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=(len(y_train[y_train==0]) / len(y_train[y_train==1])),\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Train\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(\n",
    "    y_test, y_pred_xgb, digits=4, zero_division=0\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd5b76-4f92-43ed-9cf1-32faa79fc9b6",
   "metadata": {},
   "source": [
    "** Boosting Model (XGBoost) – Interpretation**\n",
    "\n",
    "Confusion Matrix:\n",
    "- **True Negatives (TN) = 779** → correctly predicted non-churn  \n",
    "- **False Positives (FP) = 254** → predicted churn but actually non-churn  \n",
    "- **False Negatives (FN) = 95** → predicted non-churn but actually churn  \n",
    "- **True Positives (TP) = 279** → correctly predicted churn  \n",
    "\n",
    "**Classification Report Highlights:**  \n",
    "- Accuracy: 0.7520 → slightly higher than Tuned RF  \n",
    "- Recall (Churn): 0.7460 → most churners detected  \n",
    "- Precision (Churn): 0.5235 → moderate; some false positives exist  \n",
    "- F1-score (Churn): 0.6152 → balanced performance  \n",
    "- Weighted F1: 0.7634 → highest overall performance  \n",
    "\n",
    "**Key Takeaways:**  \n",
    "- XGBoost captures **complex patterns** better than RF.  \n",
    "- Recall remains high → effective for churn detection.  \n",
    "- F1-score indicates **moderate performance**; precision trade-off is acceptable.  \n",
    "- Slightly more complex and less interpretable than Random Forest; strong candidate for deployment/demo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8978c5-03a5-4962-8c25-d72701e5b155",
   "metadata": {},
   "source": [
    "#  Step6 : Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9e3b8cea-8224-4f16-9281-14aaf707dbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision_Churn</th>\n",
       "      <th>Recall_Churn</th>\n",
       "      <th>F1_Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tuned RF</th>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.751955</td>\n",
       "      <td>0.523452</td>\n",
       "      <td>0.745989</td>\n",
       "      <td>0.615215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.473262</td>\n",
       "      <td>0.529148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.727079</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>0.497326</td>\n",
       "      <td>0.492063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.734186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Precision_Churn  Recall_Churn  F1_Churn\n",
       "Tuned RF       0.746269         0.515152      0.772727  0.618182\n",
       "XGBoost        0.751955         0.523452      0.745989  0.615215\n",
       "Random Forest  0.776119         0.600000      0.473262  0.529148\n",
       "Decision Tree  0.727079         0.486911      0.497326  0.492063\n",
       "Dummy          0.734186         0.000000      0.000000  0.000000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary to store metrics\n",
    "model_metrics = {}\n",
    "\n",
    "# 1️⃣ Dummy Classifier\n",
    "model_metrics['Dummy'] = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_baseline),\n",
    "    'Precision_Churn': precision_score(y_test, y_pred_baseline, pos_label=1, zero_division=0),\n",
    "    'Recall_Churn': recall_score(y_test, y_pred_baseline, pos_label=1, zero_division=0),\n",
    "    'F1_Churn': f1_score(y_test, y_pred_baseline, pos_label=1, zero_division=0)\n",
    "}\n",
    "\n",
    "# 2️⃣ Decision Tree\n",
    "model_metrics['Decision Tree'] = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_tree),\n",
    "    'Precision_Churn': precision_score(y_test, y_pred_tree, pos_label=1, zero_division=0),\n",
    "    'Recall_Churn': recall_score(y_test, y_pred_tree, pos_label=1, zero_division=0),\n",
    "    'F1_Churn': f1_score(y_test, y_pred_tree, pos_label=1, zero_division=0)\n",
    "}\n",
    "\n",
    "# 3️⃣ Random Forest (default)\n",
    "model_metrics['Random Forest'] = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'Precision_Churn': precision_score(y_test, y_pred_rf, pos_label=1, zero_division=0),\n",
    "    'Recall_Churn': recall_score(y_test, y_pred_rf, pos_label=1, zero_division=0),\n",
    "    'F1_Churn': f1_score(y_test, y_pred_rf, pos_label=1, zero_division=0)\n",
    "}\n",
    "\n",
    "# 4️⃣ Tuned Random Forest\n",
    "model_metrics['Tuned RF'] = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_tuned),\n",
    "    'Precision_Churn': precision_score(y_test, y_pred_tuned, pos_label=1, zero_division=0),\n",
    "    'Recall_Churn': recall_score(y_test, y_pred_tuned, pos_label=1, zero_division=0),\n",
    "    'F1_Churn': f1_score(y_test, y_pred_tuned, pos_label=1, zero_division=0)\n",
    "}\n",
    "\n",
    "# 5️⃣ XGBoost\n",
    "model_metrics['XGBoost'] = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_xgb),\n",
    "    'Precision_Churn': precision_score(y_test, y_pred_xgb, pos_label=1, zero_division=0),\n",
    "    'Recall_Churn': recall_score(y_test, y_pred_xgb, pos_label=1, zero_division=0),\n",
    "    'F1_Churn': f1_score(y_test, y_pred_xgb, pos_label=1, zero_division=0)\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for pretty display\n",
    "model_comparison_df = pd.DataFrame(model_metrics).T\n",
    "model_comparison_df = model_comparison_df.sort_values(by='F1_Churn', ascending=False)\n",
    "model_comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b43c8-ddc9-48c5-9067-4febb5e28d71",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation:**\n",
    "- **Tuned Random Forest** achieves the best balance between detecting churners (recall = 0.7727) and overall performance (F1 = 0.6182).  \n",
    "- **XGBoost** has slightly higher accuracy (0.7520) but slightly lower F1 for churn, making it comparable to Tuned RF.  \n",
    "- **Default Random Forest** prioritizes precision over recall → fewer false positives, but misses many churners.  \n",
    "- **Decision Tree** shows moderate performance but is lower than ensemble models.  \n",
    "- **Dummy Classifier** performs poorly for churn (as expected), serving as the baseline.  \n",
    "\n",
    "**Key Takeaways:**\n",
    "- **Tuned Random Forest** is the most suitable model for deployment, as it balances **recall and F1** for churners.  \n",
    "- XGBoost is a strong alternative if slight accuracy gain is preferred.  \n",
    "- Ensemble models clearly outperform single decision trees and baseline.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5854bcb-e354-4611-aa2d-bba09f3b5139",
   "metadata": {},
   "source": [
    "# Step 7`: Save and Load Final Model using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3377ddb0-84fe-43d7-adc6-328ce973e63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model accuracy on test set: 0.746268656716418\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 1️⃣ Save the tuned Random Forest model\n",
    "model_filename = 'final_churn_model.pkl'\n",
    "joblib.dump(tuned_rf, model_filename)\n",
    "\n",
    "# 2️⃣ Load the model (for later use or deployment)\n",
    "loaded_model = joblib.load(model_filename)\n",
    "\n",
    "# 3️⃣ Evaluate loaded model to confirm it works\n",
    "model_score = loaded_model.score(X_test, y_test)\n",
    "print(\"Loaded model accuracy on test set:\", model_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
